type stage = string
type label = int

(** grouping *)

type grouping =
  | Split
  | Join_label
  | Join_node
  | Join_node_label
  | Join_all

val grouping_of_string : string -> grouping
val string_of_grouping : grouping -> string

(** pipelines *)

type pipeline = (stage * grouping) list

val pipeline_of_string : string -> pipeline
val pipeline_of_json : Json.t -> pipeline
val json_of_pipeline : pipeline -> Json.t

type pipeline_error =
  | Invalid_grouping of string
  | Invalid_pipeline_json of Json.t
  | Invalid_pipeline_stage of string
  | Invalid_pipeline of string

exception Pipeline_error of pipeline_error

val string_of_pipeline_error : pipeline_error -> string

(** job inputs

    These are the data input specifications that appear in jobpacks.
    Each input is specified by a set of urls for replicas, a label,
    and a size.  The size can be 0 if the actual data size is unknown.
*)

type data_size = int
type job_input = label * data_size * Uri.t list

val job_input_of_string : string -> job_input
val job_input_of_json : Json.t -> job_input
val json_of_job_input : job_input -> Json.t

type job_input_error =
  | Invalid_job_input_json of Json.t
  | Invalid_job_input_string of string
  | Invalid_job_input_label of string
  | Invalid_job_input_size of string
  | Invalid_job_input_url of string
  | Invalid_job_input of string

exception Job_input_error of job_input_error

val string_of_job_input_error : job_input_error -> string

(** task inputs

    These are the data input specifications that are provided to
    invoked Disco tasks.

    Task inputs in Disco are usually of two types:

    A "Data" input is a labelled blob of data available at multiple
    locations (or replicas).  Each location is specified by a "data"
    url, and the integer label is attached to the url using the '#'
    fragment syntax:

      task_input_url = data_url#label

    Data inputs are generally used as inputs to the entire job
    pipeline, and the multiple locations typically originate from the
    replicas in DDFS.

    A "Dir" input is an "directory index" file that contains entries
    for labelled data files, with one entry per line.  The format for
    each entry is:

      label url_to_data_file data_file_size

    The data_files typically contain intermediate results generated by
    tasks in the pipeline.  The url_to_data_file are normal unlabelled
    urls (i.e. they do not contain '#' fragments).

    A task input that is a url pointing to a "Dir" input file is
    specified using a 'dir://' scheme with an optional label in the
    usual '#' fragment notation:

      'dir'://host/path[#label]

    The 'dir' scheme is treated like the 'disco' scheme: the
    conversion to the actual underlying url is performed as follows:

      'dir'|'disco'://host/path  ->  'http'://host:$DISCO_PORT/path

    If a task receives a "Dir" url with no label fragment, it needs to
    process _all_ the data entries in the index file pointed to by the
    actual url.  If the "Dir" url has a label fragment, then the task
    needs to process only the entries with the specified label.
 *)
type task_input =
  | Data of label * Uri.t
        (** the uri specifies the location of labelled raw data *)
  | Dir_indexed of label * Uri.t
        (** the uri points to an input index, and the only the entries
            from the index that match the specified label constitute
            input data *)
  | Dir of Uri.t
        (** the uri points to an input index, and all the entries in
            the index constitute input data *)

val uri_of : task_input -> Uri.t

val comparable_task_inputs :
    Protocol.replica_id * task_input -> Protocol.replica_id * task_input -> bool

val task_input_of : Protocol.taskinfo -> Protocol.input_id
  -> Protocol.replica list -> (Protocol.replica_id * task_input) list
